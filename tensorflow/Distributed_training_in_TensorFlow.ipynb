{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed-training-in-TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNizW/ArGW89UJQT6SV0Nmj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d4184ced5af412f8ba410fed9200e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0ca91febc5f345e19fe126df325de724",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b02fc38e3aa84d3f91334f1b5cddd29f",
              "IPY_MODEL_54bea0fcb16046849523d7c00ceadc37"
            ]
          }
        },
        "0ca91febc5f345e19fe126df325de724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b02fc38e3aa84d3f91334f1b5cddd29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57b6461099e84152b919053c16260b88",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d05979826dad43e08c75585b5d29a1a9"
          }
        },
        "54bea0fcb16046849523d7c00ceadc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92d450b37d1a436f848b46acb3dc7bcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:13&lt;00:00,  7.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe51023cf47348579c55c4c6b602b762"
          }
        },
        "57b6461099e84152b919053c16260b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d05979826dad43e08c75585b5d29a1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92d450b37d1a436f848b46acb3dc7bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe51023cf47348579c55c4c6b602b762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sen-R/tutorials-dl/blob/master/tensorflow/Distributed_training_in_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJuO0aC2iBnr"
      },
      "source": [
        "# Distributed training in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my1l5T5giGxr"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The `tf.distribute` library is designed to make training with multiple accelerators / multiple workers easier. The *strategy* concept abstracts out many aspects of distributed training so that model definition and training code can be kept agnostic about the hardware that will be used to train the model.\n",
        "\n",
        "In this notebook, we will cover the basic concepts of what a strategy is and how the `tf.distribute` library can be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAZ6zvJxanaU"
      },
      "source": [
        "## Basic concepts in distributed training\n",
        "\n",
        "There are many levels at which to parallelise computation for deep learning:\n",
        "* Use multiple machines - i.e. each an entire computer, with processing (including potentially hardware accelerators), memory and communication capabilities;\n",
        "* Use multiple hardware accelerators (GPUs) on a single computer;\n",
        "* Invoking highly parallel computation of tensor operations within a processor.\n",
        "\n",
        "Of these, the last is automatically accomplished through the use of even a single GPU or other dedicated accelerators. However, to speed tasks up further, it could be desirable parallelise further, by using multiple accelerators or even multiple workers. Furthermore, if you wish to use a TPU, even a single TPU node consists of 8 cores, so distributed computation is compulsory. This is where `tf.distribute` comes in.\n",
        "\n",
        "Whether you are using multiple workers, multiple accelerators or a combination of the two, the next step is to decide how you wish to parallelise your computation. In this context, we are typically talking about parallelising the training loop that searches for optimal weights for a neural network.\n",
        "\n",
        "Recall that the key steps in a training loop are, given a batch of training data:\n",
        "1. The forward pass: compute the model outputs and thus loss on the batch;\n",
        "2. The backward pass: compute gradients with respect to model parameters;\n",
        "3. Update weights: perform an update of the model weights using the computed gradients and the chosen optimisation algorithm.\n",
        "\n",
        "Also, note that for most network architectures and loss functions, there is no or little (in the case of batch normalisation) interdependency between examples in a given batch during the forward and backward pass steps. The collective impact of individual examples only really comes together when a reduction (such as calculating the mean) is performed on the per-example loss and its corresponding gradients.\n",
        "\n",
        "Hence, a tidy way to divide labour between multiple devices would be to split a batch up further into sub-batches, to be sent to each device to perform the forward and backward passes in isolation. When the individual computations are done, the devices talk to each other to compute aggregate gradients and update the model weights accordingly. Note that to take this approach, each device would have to hold its own copy of the model (which would hence need to fit in that device's memory) - called a *replica* of the model - and we need to ensure that each device updates the weights of the model identically.\n",
        "\n",
        "This approach is called *synchronised* training and is the focus of this notebook. It is conceptually the tidiest and most reliable form of parallelism, in the sense that the evolution of model parameters during training should end up being identical to how parameters would have evolved under single-device training. The downside of this approach is that, since each weight update happens in lock-step, the speed-up of this form of distributed training is limited by the slowest device in the cluster and also by the communications bandwidth available for sharing gradients between replicas to update weights (which could be significant when we are talking about multi-worker parallelism). An alternative approach is *asynchronous* training, where individual devices do not wait for each other, but this is not covered here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky4Wo76Sh5Zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a627ea-4cd5-4cd8-870c-72be62a94abc"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKI3uk-_h38t"
      },
      "source": [
        "## Strategies\n",
        "\n",
        "A strategy is the object that takes care of distribution for you. Strategies are used to accomplish several aspects of distributed training:\n",
        "\n",
        "* Control the placement of data across multiple devices, ensuring where appropriate (e.g. model weights) identical data are mirrored across devices and elsewhere where appropriate (e.g. training data) that batches of data are sharded across devices.\n",
        "* Perform the same operations in parallel across all devices.\n",
        "* Gather and / or reduce the per-device results.\n",
        "\n",
        "The strategies we will cover in this tutorial include:\n",
        "* The default strategy, returned by `tf.distribute.get_strategy`, which actually performs no distribution, but can be used run code that requires a strategy.\n",
        "* The `MirroredStrategy` that mirrors variables (including model weights) across all devices in scope to perform synchronised training.\n",
        "* The `TPUStrategy` which is used for trainin on TPUs but is conceptually similar to the `MirroredStrategy`.\n",
        "\n",
        "We will not specifically discuss these other strategies:\n",
        "* The `OneDeviceStrategy` that is similar to the default strategy in that it does not perform any parallelism but it does ensure computation takes place on the specified device.\n",
        "* The `MultiWorkerMirroredStrategy` that is conceptually similar to the `MirroredStrategy` but allows for devices to be attached to multiple workers (rather than a single worker).\n",
        "* The `CentralStorageStrategy` that like the `MirroredStrategy` performs synchronised training, but with model parameters held centrally on a single device (either the CPU if there are multiple GPUs, or the GPU if there is only a single GPU).\n",
        "* The `ParameterServerStrategy` which can be used for asynchronous training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhLi0KOsmSvG"
      },
      "source": [
        "### Choosing a strategy\n",
        "\n",
        "Simply instantiate a strategy object using the desired `Strategy` subclass. Here we create a `MirroredStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nbASSbhl3vJ",
        "outputId": "2aa777b4-247f-4dc4-e98a-d41d3647e4eb"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy(devices=[\"/CPU:0\", \"/GPU:0\"])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2X7UoWemt5z"
      },
      "source": [
        "Note that since Colab does not provide multiple GPU acceleration (and we don't want to use TPU acceleration unnecessarily) I have forced the strategy to use both the CPU and single available GPU for mirrored training. This is clearly not an efficient setup for actual training, but will be fine for demonstrating how to use this strategy.\n",
        "\n",
        "Let us begin by checking the number of model replicas in the strategy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7rEToCdmn9C",
        "outputId": "32be5368-10a5-4b89-aaa9-a93bfaee023a"
      },
      "source": [
        "print(\"Number of replicas in strategy:\", strategy.num_replicas_in_sync) # should be 2\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of replicas in strategy: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzUVrOqhz_Xv"
      },
      "source": [
        "### Basic usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Tpm0sbnqUf"
      },
      "source": [
        "#### Variable placement\n",
        "\n",
        "Strategies have an associated scope, accessed using the `scope` method. Variables created within that scope (including variables created within functions called within that scope) are automatically replicated across all devices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHZnKfoHncwl",
        "outputId": "1f9ac717-0fb5-47b1-bea0-47ee088f2f03"
      },
      "source": [
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.weight = tf.Variable(3.14, dtype=tf.float32)\n",
        "\n",
        "# Non-replicated instantiation of MyClass\n",
        "nonrep = MyClass()\n",
        "print(\"nonrep.weight:\", nonrep.weight)\n",
        "print()\n",
        "\n",
        "with strategy.scope():\n",
        "    # Replicated instantiation of MyClass\n",
        "    rep = MyClass()\n",
        "print(\"rep.weight:\", rep.weight)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nonrep.weight: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.14>\n",
            "\n",
            "rep.weight: MirroredVariable:{\n",
            "  0: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.14>,\n",
            "  1: <tf.Variable 'Variable/replica_1:0' shape=() dtype=float32, numpy=3.14>\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsytwQynpdcd"
      },
      "source": [
        "As you can see, when an object is created outside of strategy scope (`nonrep`), variables are just created on the default device. However, when the same class is instantiated within strategy scope (`rep`), variables held by that object are of type `MirroredVariable` and are replicated across both devices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRv__fBbM48U"
      },
      "source": [
        "#### Running code\n",
        "\n",
        "We can use `strategy.run` to run code in \"replica scope\". Semantically, code run in replica scope runs almost as if it is running purely on a single device, independent of others. I said \"almost\" because there are certain operations, like variable assignment that may first use cross device communication, to ensure variable updates remain in sync."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ef4NbfzNUL9",
        "outputId": "1f656a15-e453-4a52-e0d1-a73a9f3cd9af"
      },
      "source": [
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "res = strategy.run(add, args=(tf.constant([[1, 2]]), tf.constant([[3, 4]])))\n",
        "print(res)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PerReplica:{\n",
            "  0: tf.Tensor([[4 6]], shape=(1, 2), dtype=int32),\n",
            "  1: tf.Tensor([[4 6]], shape=(1, 2), dtype=int32)\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNI5L_uFNprr"
      },
      "source": [
        "There are also methods to collect per-replica results into a tuple, concatenate them into a tensor or perform a reduction on them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txy7PAzvN6to",
        "outputId": "3baeea2c-9c82-41d4-d6dc-956c2a1d981c"
      },
      "source": [
        "print(\"strategy.experimental_local_results:\")\n",
        "print(strategy.experimental_local_results(res))\n",
        "print()\n",
        "\n",
        "print(\"strategy.gather:\")\n",
        "print(strategy.gather(res, axis=0))\n",
        "print()\n",
        "\n",
        "print(\"strategy.reduce:\")\n",
        "print(strategy.reduce(\"SUM\", res, axis=0))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "strategy.experimental_local_results:\n",
            "(<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[4, 6]], dtype=int32)>, <tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[4, 6]], dtype=int32)>)\n",
            "\n",
            "strategy.gather:\n",
            "INFO:tensorflow:Gather to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "tf.Tensor(\n",
            "[[4 6]\n",
            " [4 6]], shape=(2, 2), dtype=int32)\n",
            "\n",
            "strategy.reduce:\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "tf.Tensor([ 8 12], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmrIphmu0FWE"
      },
      "source": [
        "#### Data sharding\n",
        "\n",
        "On the other hand, we want data from input datasets to be sharded across devices. This is achieved by calling the `experimental_distribute_dataset` method on a TensorFlow `Dataset` object.\n",
        "\n",
        "In the following code, we first create a \"dataset\" consisting of the numbers from 0 to 15, batched into chunks of 4, and distribute it across the two devices. Sharding means the original size 4 batches will be sub-divided into size 2 batches, one-per device, as you can see from the output below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-8Bu6A3pc5s",
        "outputId": "747a399a-d184-41da-a0fa-ec7408022779"
      },
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices(tf.range(16)).batch(4)\n",
        "dds = strategy.experimental_distribute_dataset(ds)\n",
        "\n",
        "@tf.function\n",
        "def return_batch(batch):\n",
        "    \"\"\"No-op: just returns the batch as-is\"\"\"\n",
        "    return {\"replica\": tf.distribute.get_replica_context().replica_id_in_sync_group, \"batch\": batch, }\n",
        "\n",
        "def dataset_distribution_experiment(dataset):\n",
        "    for idx, batch in enumerate(dataset):\n",
        "        print(\"Global batch #:\", idx)\n",
        "        results = strategy.experimental_local_results(strategy.run(return_batch, args=(batch,)))\n",
        "        print(\"Results:\", [{k: v.numpy() for k, v in d.items()} for d in results])\n",
        "        print(\"\")\n",
        "\n",
        "print(\"Original dataset (not sharded):\")\n",
        "print(\"===============================\")\n",
        "dataset_distribution_experiment(ds)\n",
        "print()\n",
        "print()\n",
        "print(\"Distributed dataset:\")\n",
        "print(\"====================\")\n",
        "dataset_distribution_experiment(dds)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset (not sharded):\n",
            "===============================\n",
            "Global batch #: 0\n",
            "Results: [{'replica': 0, 'batch': array([0, 1, 2, 3], dtype=int32)}, {'replica': 1, 'batch': array([0, 1, 2, 3], dtype=int32)}]\n",
            "\n",
            "Global batch #: 1\n",
            "Results: [{'replica': 0, 'batch': array([4, 5, 6, 7], dtype=int32)}, {'replica': 1, 'batch': array([4, 5, 6, 7], dtype=int32)}]\n",
            "\n",
            "Global batch #: 2\n",
            "Results: [{'replica': 0, 'batch': array([ 8,  9, 10, 11], dtype=int32)}, {'replica': 1, 'batch': array([ 8,  9, 10, 11], dtype=int32)}]\n",
            "\n",
            "Global batch #: 3\n",
            "Results: [{'replica': 0, 'batch': array([12, 13, 14, 15], dtype=int32)}, {'replica': 1, 'batch': array([12, 13, 14, 15], dtype=int32)}]\n",
            "\n",
            "\n",
            "\n",
            "Distributed dataset:\n",
            "====================\n",
            "Global batch #: 0\n",
            "Results: [{'replica': 0, 'batch': array([0, 1], dtype=int32)}, {'replica': 1, 'batch': array([2, 3], dtype=int32)}]\n",
            "\n",
            "Global batch #: 1\n",
            "Results: [{'replica': 0, 'batch': array([4, 5], dtype=int32)}, {'replica': 1, 'batch': array([6, 7], dtype=int32)}]\n",
            "\n",
            "Global batch #: 2\n",
            "Results: [{'replica': 0, 'batch': array([8, 9], dtype=int32)}, {'replica': 1, 'batch': array([10, 11], dtype=int32)}]\n",
            "\n",
            "Global batch #: 3\n",
            "Results: [{'replica': 0, 'batch': array([12, 13], dtype=int32)}, {'replica': 1, 'batch': array([14, 15], dtype=int32)}]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAgG8cFtPFFT"
      },
      "source": [
        "As the output shows, if we fail to distribute the dataset, the same (global, size 4) batches will be fed to both replicas, meaning we fail to derive any advantage from distributed training. However, by distributing the dataset, each replica receives one half of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfuJmubg16X-"
      },
      "source": [
        "#### Coordinated variable updates\n",
        "\n",
        "The last ingredient for distributed training is to update replicated variables in a coordinated manner. I.e., after backpropagation on their respective sub-batches, each replica will hold a different gradient tensor (with respect to the same model weights). To perform synchronised training, we need to ensure that these different gradients are combined to single value that is then used by the optimisation algorithm to update weight variables in all the replicas.\n",
        "\n",
        "For variables created in strategy scope, this is taken care of automatically when using any of the variable `assign` methods. The only requirement is to specify, when the variable is created, how updates should be aggregated across replicas before being assigned. In the following example, we will create a mirrored \"running_sum\" variable that needs to be updated with values from the distributed dataset we created earlier. We want to add the results from each replica first before we use `assign_add`, so we set `aggregation=tf.VariableAggregation.SUM` when creating the variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H38FP377d4O",
        "outputId": "1f909304-d730-4c33-9ab8-c4419e70c65e"
      },
      "source": [
        "class RunningSum:\n",
        "    def __init__(self, aggregation):\n",
        "        self.result = tf.Variable(0, dtype=tf.int32, aggregation=aggregation)\n",
        "\n",
        "    @tf.function\n",
        "    def update(self, value):\n",
        "        self.result.assign_add(tf.reduce_sum(value))\n",
        "\n",
        "def assignment_experiment(aggregation, strategy, dataset):\n",
        "    with strategy.scope():\n",
        "        rs = RunningSum(aggregation)\n",
        "    for val in dataset:\n",
        "        strategy.run(rs.update, args=(val,))\n",
        "    return rs.result\n",
        "\n",
        "print(\n",
        "    \"Per replica variables diverge without aggregation (as each device \"\n",
        "    \"only updates according to the values it sees):\"\n",
        ")\n",
        "print(assignment_experiment(tf.VariableAggregation.NONE, strategy, dds))\n",
        "print()\n",
        "print(\n",
        "    \"But setting aggregation to SUM keeps the variables in sync and yields \"\n",
        "    \"the correct result for the sum of the dataset (i.e. 120):\"\n",
        ")\n",
        "print(assignment_experiment(tf.VariableAggregation.SUM, strategy, dds))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Per replica variables diverge without aggregation (as each device only updates according to the values it sees):\n",
            "MirroredVariable:{\n",
            "  0: <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=52>,\n",
            "  1: <tf.Variable 'Variable/replica_1:0' shape=() dtype=int32, numpy=68>\n",
            "}\n",
            "\n",
            "But setting aggregation to SUM keeps the variables in sync and yields the correct result for the sum of the dataset (i.e. 120):\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "MirroredVariable:{\n",
            "  0: <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=120>,\n",
            "  1: <tf.Variable 'Variable/replica_1:0' shape=() dtype=int32, numpy=120>\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsRgd10l_jam"
      },
      "source": [
        "However, this is *not* how coordination of variable aggregation is done with Tensorflow's optimisers. This is presumably because there is a reliance on users having set the `aggregation` property of variables correctly for this approach to work. Instead, optimisers instead use the pattern and functions described [here](https://www.tensorflow.org/api_docs/python/tf/distribute/StrategyExtended) to perform coordinated gradient updates.\n",
        "\n",
        "Finally, in practice, it is unlikely we ever need to worry about these details for deep learning applications. This is because TensorFlow's `Optimizer` base class (and therefore correctly implemented subclasses) takes care of this for us (summing gradients by default) within the `apply_gradients` method. This can be overridden by using the `experimental_aggregate_gradients` option, which may be useful for aggregating processed gradient, as discussed further in the documentation for [`Optimizer`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer#use_with_tfdistributestrategy_2).\n",
        "\n",
        "See the [custom training loop](#custom_training_loops) section below for an example of how to use an `Optimizer` within a strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUPxMW6hBliD"
      },
      "source": [
        "## Using strategies with Keras\n",
        "\n",
        "To use Keras (and its standard training loop) with a strategy is simple as the library is strategy aware. Apart from creating the model within the `strategy.scope()` context, the key differences are in preparing the dataset:\n",
        "\n",
        "* Remember to distribute the dataset\n",
        "* The dataset needs to be repeated as many times as there are epochs, and the number of steps per epoch need to be passed to the `model.fit` method. This is presumably because distributed datasets do not have a `__len__` method and furthermore the generator is not re-created at the end of each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzuR2zxRBst",
        "outputId": "ce4837bf-316e-4f84-d793-931cf6b61fac"
      },
      "source": [
        "# Create training data\n",
        "X = tf.range(0, 20, dtype=tf.float32)[:, tf.newaxis]\n",
        "y = 2. * X + 3\n",
        "train = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "\n",
        "# Distribute dataset\n",
        "EPOCHS = 100\n",
        "PER_REPLICA_BATCH_SIZE = 2\n",
        "GLOBAL_BATCH_SIZE = PER_REPLICA_BATCH_SIZE * strategy.num_replicas_in_sync\n",
        "STEPS_PER_EPOCH = len(train) // GLOBAL_BATCH_SIZE\n",
        "dist_train = strategy.experimental_distribute_dataset(\n",
        "    train.batch(GLOBAL_BATCH_SIZE).repeat(EPOCHS)\n",
        ")\n",
        "\n",
        "# Create model in cross-replica scope and fit, otherwise as usual\n",
        "def create_and_compile_model():\n",
        "    model = tf.keras.models.Sequential(\n",
        "        [tf.keras.layers.Dense(1, input_shape=(1,))]\n",
        "    )\n",
        "    loss = tf.keras.losses.MeanSquaredError()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "    metrics = [tf.keras.metrics.mean_absolute_error]\n",
        "    model.compile(\n",
        "        loss=loss, optimizer=optimizer, metrics=metrics\n",
        "    )\n",
        "    return model\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_and_compile_model()\n",
        "    history = model.fit(\n",
        "        dist_train,\n",
        "        steps_per_epoch=STEPS_PER_EPOCH,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "print(\n",
        "    \"Training complete, final loss {:.6f}.\".format(history.history[\"loss\"][-1])\n",
        ")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "Training complete, final loss 0.024162.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZJNp9bnRCN3"
      },
      "source": [
        "### Saving and checkpointing\n",
        "\n",
        "When a model is created within the `strategy.scope()` context, its variables are (as to be expected) distributed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62FvzAqzE4Zo",
        "outputId": "89bcbf86-c36a-4a41-f2f5-5b57061c6bd5"
      },
      "source": [
        "print(model.layers[0].kernel)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MirroredVariable:{\n",
            "  0: <tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9768484]], dtype=float32)>,\n",
            "  1: <tf.Variable 'dense/kernel/replica_1:0' shape=(1, 1) dtype=float32, numpy=array([[1.9768559]], dtype=float32)>\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCnG-zJgFIzs"
      },
      "source": [
        "However, when you call `model.get_weights`, just one set of weights is returned (as for non-distributed models):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRYRsfhME_XI",
        "outputId": "722851c0-3c93-4c82-e4e6-6da495fc8420"
      },
      "source": [
        "print(model.get_weights())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[1.9768484]], dtype=float32), array([3.2932746], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcJwWESaFO4w"
      },
      "source": [
        "This means that saving and checkpointing models is the same as without `tf.distribute`. In fact, you can even save a model that was trained using a certain strategy and load the weights onto a model that was created using a different strategy / without any strategy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugpWsXa7GCMf",
        "outputId": "8c2b0655-6e94-4887-9c2d-66aeab429edc"
      },
      "source": [
        "# Save original model\n",
        "model.save_weights(\"ckpt\")\n",
        "\n",
        "# Create new (unreplicated model)\n",
        "nonrep_model = create_and_compile_model()\n",
        "nonrep_model.load_weights(\"ckpt\")\n",
        "\n",
        "# Check model performance\n",
        "perf = nonrep_model.evaluate(train.batch(GLOBAL_BATCH_SIZE))\n",
        "print(\"Loaded model loss: {:.6f}\".format(perf[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0232 - mean_absolute_error: 0.1273\n",
            "Loaded model loss: 0.023200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL_ANZl7HJVu"
      },
      "source": [
        "One noteworthy point about the outputs above is that during distributed training it is possible for \"mirrored\" variables' values to diverge slightly between supposedly identical replicas. (Look at the values for the kernel of the dense layer above.) This is actually not surprising, particularly when the replicas are on different device types (a CPU and GPU in this case) as even where the same operations are performed, numerical errors can cause precise values to diverge.\n",
        "\n",
        "Looking at the outputs of `model.get_weights()` above it seems that the weights for replica id 0 are the \"authoritative\" weights that get saved. It would be interesting (at some point) to investigate just how far weights can diverge between replicas in practice (for real problems) and how much of an issue this could pose for the reliability of distributed training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAXJYRQcBuGM"
      },
      "source": [
        "### Custom training loops\n",
        "<a name=\"custom_training_loops\"/>\n",
        "\n",
        "In a custom training loop, it is important to set the loss function up correctly. You don't want to average the loss within a replica, but instead divide by the global (across-all-replicas) batch size. This way, when the optimizer's `apply_gradients` method sums gradients across all replicas (or you do it manually using reduce to record the loss) this will be for the actual average loss across the whole batch.\n",
        "\n",
        "This is the pattern suggested in the [TensorFlow guide](https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "6d4184ced5af412f8ba410fed9200e57",
            "0ca91febc5f345e19fe126df325de724",
            "b02fc38e3aa84d3f91334f1b5cddd29f",
            "54bea0fcb16046849523d7c00ceadc37",
            "57b6461099e84152b919053c16260b88",
            "d05979826dad43e08c75585b5d29a1a9",
            "92d450b37d1a436f848b46acb3dc7bcf",
            "fe51023cf47348579c55c4c6b602b762"
          ]
        },
        "id": "QPZE0rT9Leqj",
        "outputId": "3bd7e915-a28c-4e45-a81c-905e3a9efe8a"
      },
      "source": [
        "pe_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "def compute_loss(labels, predictions):\n",
        "    per_example_loss = pe_loss(labels,predictions)\n",
        "    return tf.nn.compute_average_loss(\n",
        "        per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE\n",
        "    )\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, model):\n",
        "    features, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(features, training=True)\n",
        "        loss = compute_loss(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def distributed_train_step(dist_inputs, model, strategy):\n",
        "    per_replica_losses = strategy.run(train_step, args=(dist_inputs, model))\n",
        "    return strategy.reduce(\"SUM\", per_replica_losses, axis=None)\n",
        "\n",
        "def distributed_train(dist_inputs, model, strategy, steps_per_epoch, epochs):\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        iterator = iter(dist_inputs)\n",
        "        for step in range(steps_per_epoch):\n",
        "            batch = next(iterator)\n",
        "            distributed_train_step(batch, model, strategy)\n",
        "\n",
        "with strategy.scope():\n",
        "    cust_train_model = create_and_compile_model()\n",
        "distributed_train(dist_train, cust_train_model, strategy, STEPS_PER_EPOCH, EPOCHS)\n",
        "perf = cust_train_model.evaluate(dist_train, steps=STEPS_PER_EPOCH)\n",
        "print(\"Model trained, loss: {:.6f}\".format(perf[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d4184ced5af412f8ba410fed9200e57",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
            "\n",
            "5/5 [==============================] - 3s 4ms/step - loss: 2.5538e-04 - mean_absolute_error: 0.0133\n",
            "Model trained, loss: 0.000255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE3JJ0chOIoH"
      },
      "source": [
        "## Using TPUs for training\n",
        "\n",
        "**Note: you will need to switch runtime type to TPU before running the code in this section**\n",
        "\n",
        "First initialize your TPU using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXL_eztDiFTL",
        "outputId": "3b8092dd-4cca-4a8a-888d-0bd5b22795dd"
      },
      "source": [
        "import tensorflow as tf\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"TPU devices available:\", tf.config.list_logical_devices(\"TPU\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.236.66:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.236.66:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU devices available: [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpgtrNTAiVmo"
      },
      "source": [
        "It is now possible to use manual device placement to place computations on a named TPU device. However, typically you will want to use `TPUStrategy` to distribute training across all available TPU devices and manage variable / model placement for you.\n",
        "\n",
        "Obtain the strategy as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mwswwSIipLm",
        "outputId": "f63f19d0-51bf-40e5-ea7e-46494b7537dc"
      },
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRsveJMGit72"
      },
      "source": [
        "Now, code designed to work with any strategy can be run on all available TPUs. See the [TensorFlow guide](https://www.tensorflow.org/guide/tpu) for a standard example (classification with MNIST).\n",
        "\n",
        "Note that except where a `Dataset` has been generated from in-graph data (e.g. using `from_tensor_slices`) the underlying datafiles will need to be in a GCS bucket. For `tfds` datasets, this is achieved by using setting the `try_gcs` keyword argument to `True` when calling `tfds.load`. The guide has several other tips for maximising performance on TPUs (the key themes to be to try and eliminate bottlenecks caused by loading data and CPU-based processing)."
      ]
    }
  ]
}
